{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should run this after preprocessing\n",
    "# Iterate the feature_extract function according to the \"tracks_with_genre_small.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE_HOME='../datasets/fma_small_flatten/'\n",
    "FEATURE_OUTPUT_HOME='./features'\n",
    "META_FILE = '../preprocessing/datasets/tracks_with_genre_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, columns, output_filename):\n",
    "    df = pd.DataFrame([data], columns=columns)\n",
    "    df.to_csv(f\"{FEATURE_OUTPUT_HOME}/{output_filename}\", mode='a', header=False, index=False)\n",
    "\n",
    "def extract_feature(y, sr, feature_func, *args, **kwargs):\n",
    "    return feature_func(y=y, sr=sr, *args, **kwargs)\n",
    "\n",
    "def extract_zero_crossings(y, sr, filename, output_filename):\n",
    "    zero_crossings = np.sum(lb.zero_crossings(y))\n",
    "    save_to_csv([filename, zero_crossings], ['track_id', 'zero_crossings'], output_filename)\n",
    "\n",
    "def extract_tempo(y, sr, filename, output_filename):\n",
    "    onset_env = lb.onset.onset_strength(y=y, sr=sr)\n",
    "    tempo, _ = lb.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    save_to_csv([filename, tempo], ['track_id', 'tempo'], output_filename)\n",
    "\n",
    "def extract_spectral_centroid(y, sr, filename, output_filename):\n",
    "    spectral_centroid = extract_feature(y, sr, lb.feature.spectral_centroid)\n",
    "    save_to_csv([filename, np.mean(spectral_centroid)], ['track_id', 'spectral_centroid'], output_filename)\n",
    "\n",
    "def extract_spectral_rolloff(y, sr, filename, output_filename):\n",
    "    spectral_rolloff = extract_feature(y, sr, lb.feature.spectral_rolloff)\n",
    "    save_to_csv([filename, np.mean(spectral_rolloff)], ['track_id', 'spectral_rolloff'], output_filename)\n",
    "\n",
    "def extract_chroma_stft(y, sr, filename, output_filename):\n",
    "    chroma_stft = extract_feature(y, sr, lb.feature.chroma_stft)\n",
    "    data = [filename] + list(np.mean(chroma_stft, axis=1))\n",
    "    save_to_csv(data, ['track_id'] + [f'chroma_stft_{i}' for i in range(1, 13)], output_filename)\n",
    "\n",
    "def extract_mfccs(y, sr, filename, output_filename):\n",
    "    mfccs = extract_feature(y, sr, lb.feature.mfcc, n_mfcc=20)\n",
    "    data = [filename] + list(np.mean(mfccs, axis=1))\n",
    "    save_to_csv(data, ['track_id'] + [f'MFCC_{i}' for i in range(1, 21)], output_filename)\n",
    "\n",
    "def extract_harmony_percussive(y, sr, filename, output_filename):\n",
    "    y_harmonic, y_percussive = lb.effects.hpss(y)\n",
    "    rms_harmonic = np.mean(lb.feature.rms(y=y_harmonic))\n",
    "    rms_percussive = np.mean(lb.feature.rms(y=y_percussive))\n",
    "    save_to_csv([filename, rms_harmonic, rms_percussive], ['track_id', 'rms_harmonic', 'rms_percussive'], output_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV headers\n",
    "headers = {\n",
    "    'zero_crossings.csv': ['track_id', 'zero_crossings'],\n",
    "    'tempo.csv': ['track_id', 'tempo'],\n",
    "    'spectral_centroid.csv': ['track_id', 'spectral_centroid'],\n",
    "    'spectral_rolloff.csv': ['track_id', 'spectral_rolloff'],\n",
    "    'chroma_stft.csv': ['track_id'] + [f'chroma_stft_{i}' for i in range(1, 13)],\n",
    "    'mfccs.csv': ['track_id'] + [f'MFCC_{i}' for i in range(1, 21)],\n",
    "    'hpss.csv': ['track_id', 'rms_harmonic', 'rms_percussive']\n",
    "}\n",
    "\n",
    "for key, value in headers.items():\n",
    "    pd.DataFrame(columns=value).to_csv(f\"{FEATURE_OUTPUT_HOME}/{key}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  0\n",
      "complete:  100\n",
      "complete:  200\n",
      "complete:  300\n",
      "complete:  400\n",
      "complete:  500\n",
      "complete:  600\n",
      "complete:  700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1801] error: dequantization failed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  800\n",
      "complete:  900\n",
      "complete:  1000\n",
      "complete:  1100\n",
      "complete:  1200\n",
      "complete:  1300\n",
      "complete:  1400\n",
      "complete:  1500\n",
      "complete:  1600\n",
      "complete:  1700\n",
      "complete:  1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/1108232/PycharmProjects/MADS-699-Capstone-fa23-team12/venv/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829\n",
      "\n",
      "complete:  1900\n",
      "complete:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2090\n",
      "\n",
      "complete:  2100\n",
      "complete:  2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2241\n",
      "\n",
      "complete:  2300\n",
      "complete:  2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 33361.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1365] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  2500\n",
      "complete:  2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 22401.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1365] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  2700\n",
      "complete:  2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3360) too large for available bit count (3240)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  2900\n",
      "complete:  3000\n",
      "complete:  3100\n",
      "complete:  3200\n",
      "complete:  3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1801] error: dequantization failed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  3400\n",
      "complete:  3500\n",
      "complete:  3600\n",
      "complete:  3700\n",
      "complete:  3800\n",
      "complete:  3900\n",
      "complete:  4000\n",
      "complete:  4100\n",
      "complete:  4200\n",
      "complete:  4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1773] error: part2_3_length (3328) too large for available bit count (3240)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  4400\n",
      "complete:  4500\n",
      "complete:  4600\n",
      "complete:  4700\n",
      "complete:  4800\n",
      "complete:  4900\n",
      "complete:  5000\n",
      "complete:  5100\n",
      "complete:  5200\n",
      "complete:  5300\n",
      "complete:  5400\n",
      "complete:  5500\n",
      "complete:  5600\n",
      "complete:  5700\n",
      "complete:  5800\n",
      "complete:  5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1801] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 63168.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1365] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  6000\n",
      "complete:  6100\n",
      "complete:  6200\n",
      "complete:  6300\n",
      "complete:  6400\n",
      "complete:  6500\n",
      "complete:  6600\n",
      "complete:  6700\n",
      "complete:  6800\n",
      "complete:  6900\n",
      "complete:  7000\n",
      "complete:  7100\n",
      "complete:  7200\n",
      "complete:  7300\n",
      "complete:  7400\n",
      "complete:  7500\n",
      "complete:  7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1841] error: dequantization failed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  7700\n",
      "complete:  7800\n",
      "complete:  7900\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(AUDIO_FILE_HOME)\n",
    "\n",
    "for index, filename in enumerate(file_list):\n",
    "    track_id = filename[:-4]\n",
    "    # print(f\"track_id: \", track_id)\n",
    "    # print(f\"filename: \", filename)\n",
    "    if index % 100 == 0:\n",
    "        print('complete: ', index)\n",
    "    try:\n",
    "        y, sr = lb.load(f\"{AUDIO_FILE_HOME}{filename}\") \n",
    "        extract_zero_crossings(y, sr, track_id, 'zero_crossings.csv')\n",
    "        extract_tempo(y, sr, track_id, 'tempo.csv')\n",
    "        extract_spectral_centroid(y, sr, track_id, 'spectral_centroid.csv')\n",
    "        extract_spectral_rolloff(y, sr, track_id, 'spectral_rolloff.csv')\n",
    "        extract_chroma_stft(y, sr, track_id, 'chroma_stft.csv')\n",
    "        extract_mfccs(y, sr, track_id, 'mfccs.csv')  \n",
    "        extract_harmony_percussive(y, sr, track_id, 'hpss.csv') \n",
    "    except Exception as e:\n",
    "        print(index)\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge features into a single file\n",
    "\n",
    "file_names = [\"tempo\", \"hpss\", \"spectral_centroid\", \"spectral_rolloff\", \"zero_crossings\", \"chroma_stft\", \"mfccs\"]\n",
    "\n",
    "# Using a list comprehension to read all dataframes into a list\n",
    "dfs = [pd.read_csv(f\"{FEATURE_OUTPUT_HOME}/{file_name}.csv\") for file_name in file_names]\n",
    "\n",
    "# Refactoring the merging process to be more concise\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = merged_df.merge(df, on='track_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(f\"{FEATURE_OUTPUT_HOME}/all_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
